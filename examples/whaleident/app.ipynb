{"cells":[{"cell_type":"code","execution_count":1,"source":["import os\n","import gc\n","import cv2\n","import math\n","import copy\n","import time\n","import random\n","\n","# For data manipulation\n","import numpy as np\n","import pandas as pd\n","\n","# Pytorch Imports\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import torch.nn.functional as F\n","from torch.optim import lr_scheduler\n","from torch.utils.data import Dataset, DataLoader\n","from torch.cuda import amp\n","\n","# Utils\n","import joblib\n","from tqdm import tqdm\n","from collections import defaultdict\n","\n","# Sklearn Imports\n","from sklearn.preprocessing import LabelEncoder\n","from sklearn.model_selection import StratifiedKFold\n","\n","# For Image Models\n","import timm\n","\n","# Albumentations for augmentations\n","import albumentations as A\n","from albumentations.pytorch import ToTensorV2\n","\n","# For colored terminal text\n","from colorama import Fore, Back, Style\n","b_ = Fore.BLUE\n","sr_ = Style.RESET_ALL\n","\n","import warnings\n","warnings.filterwarnings(\"ignore\")\n","\n","# For descriptive error messages\n","os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\""],"outputs":[{"output_type":"stream","name":"stderr","text":["c:\\Users\\fleet\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n","  from .autonotebook import tqdm as notebook_tqdm\n","c:\\Users\\fleet\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torchvision\\models\\detection\\anchor_utils.py:63: UserWarning: Failed to initialize NumPy: module compiled against API version 0x10 but this version of numpy is 0xf (Triggered internally at  ..\\torch\\csrc\\utils\\tensor_numpy.cpp:68.)\n","  device: torch.device = torch.device(\"cpu\"),\n"]}],"metadata":{}},{"cell_type":"code","execution_count":2,"source":["import wandb\n","\n","try:\n","    from kaggle_secrets import UserSecretsClient\n","    user_secrets = UserSecretsClient()\n","    api_key = user_secrets.get_secret(\"wandb_api\")\n","    wandb.login(key=api_key)\n","    anony = None\n","except:\n","    anony = \"must\"\n","    print('If you want to use your W&B account, go to Add-ons -> Secrets and provide your W&B access token. Use the Label name as wandb_api. \\nGet your W&B access token from here: https://wandb.ai/authorize')"],"outputs":[{"output_type":"stream","name":"stdout","text":["If you want to use your W&B account, go to Add-ons -> Secrets and provide your W&B access token. Use the Label name as wandb_api. \n","Get your W&B access token from here: https://wandb.ai/authorize\n"]}],"metadata":{}},{"cell_type":"code","execution_count":3,"source":["#training config\n","CONFIG = {\"seed\": 2022,\n","          \"epochs\": 4,\n","          \"img_size\": 448,\n","          \"model_name\": \"tf_efficientnet_b0_ns\",\n","          \"num_classes\": 15587,\n","          \"embedding_size\": 512,\n","          \"train_batch_size\": 32,\n","          \"valid_batch_size\": 64,\n","          \"learning_rate\": 1e-4,\n","          \"scheduler\": 'CosineAnnealingLR',\n","          \"min_lr\": 1e-6,\n","          \"T_max\": 500,\n","          \"weight_decay\": 1e-6,\n","          \"n_fold\": 5,\n","          \"n_accumulate\": 1,\n","          \"device\": torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\"),\n","          # ArcFace Hyperparameters\n","          \"s\": 30.0, \n","          \"m\": 0.50,\n","          \"ls_eps\": 0.0,\n","          \"easy_margin\": False\n","          }"],"outputs":[],"metadata":{}},{"cell_type":"code","execution_count":4,"source":["#set seed for the entire notebook\n","def set_seed(seed=42):\n","    '''Sets the seed of the entire notebook so results are the same every time we run.\n","    This is for REPRODUCIBILITY.'''\n","    np.random.seed(seed)\n","    torch.manual_seed(seed)\n","    torch.cuda.manual_seed(seed)\n","    # When running on the CuDNN backend, two further options must be set\n","    torch.backends.cudnn.deterministic = True\n","    torch.backends.cudnn.benchmark = False\n","    # Set a fixed value for the hash seed\n","    os.environ['PYTHONHASHSEED'] = str(seed)\n","    \n","set_seed(CONFIG['seed'])"],"outputs":[],"metadata":{}},{"cell_type":"code","execution_count":5,"source":["#dirs\n","ROOT_DIR = ''\n","TRAIN_DIR = '../train_images'\n","TEST_DIR = '../test_images'\n","\n","def get_train_file_path(id):\n","    return f\"{TRAIN_DIR}/{id}\""],"outputs":[],"metadata":{}},{"cell_type":"code","execution_count":6,"source":["df = pd.read_csv(f\"{ROOT_DIR}train.csv\")\n","df['file_path'] = df['image'].apply(get_train_file_path)\n","df.head()"],"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>image</th>\n","      <th>species</th>\n","      <th>individual_id</th>\n","      <th>file_path</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>00021adfb725ed.jpg</td>\n","      <td>melon_headed_whale</td>\n","      <td>cadddb1636b9</td>\n","      <td>../train_images/00021adfb725ed.jpg</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>000562241d384d.jpg</td>\n","      <td>humpback_whale</td>\n","      <td>1a71fbb72250</td>\n","      <td>../train_images/000562241d384d.jpg</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0007c33415ce37.jpg</td>\n","      <td>false_killer_whale</td>\n","      <td>60008f293a2b</td>\n","      <td>../train_images/0007c33415ce37.jpg</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0007d9bca26a99.jpg</td>\n","      <td>bottlenose_dolphin</td>\n","      <td>4b00fe572063</td>\n","      <td>../train_images/0007d9bca26a99.jpg</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>00087baf5cef7a.jpg</td>\n","      <td>humpback_whale</td>\n","      <td>8e5253662392</td>\n","      <td>../train_images/00087baf5cef7a.jpg</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                image             species individual_id  \\\n","0  00021adfb725ed.jpg  melon_headed_whale  cadddb1636b9   \n","1  000562241d384d.jpg      humpback_whale  1a71fbb72250   \n","2  0007c33415ce37.jpg  false_killer_whale  60008f293a2b   \n","3  0007d9bca26a99.jpg  bottlenose_dolphin  4b00fe572063   \n","4  00087baf5cef7a.jpg      humpback_whale  8e5253662392   \n","\n","                            file_path  \n","0  ../train_images/00021adfb725ed.jpg  \n","1  ../train_images/000562241d384d.jpg  \n","2  ../train_images/0007c33415ce37.jpg  \n","3  ../train_images/0007d9bca26a99.jpg  \n","4  ../train_images/00087baf5cef7a.jpg  "]},"metadata":{},"execution_count":6}],"metadata":{}},{"cell_type":"code","execution_count":7,"source":["encoder = LabelEncoder()\n","df['individual_id'] = encoder.fit_transform(df['individual_id'])\n","\n","with open(\"le.pkl\", \"wb\") as fp:\n","    joblib.dump(encoder, fp)"],"outputs":[],"metadata":{}},{"cell_type":"code","execution_count":8,"source":["#create folds\n","skf = StratifiedKFold(n_splits=CONFIG['n_fold'])\n","\n","for fold, ( _, val_) in enumerate(skf.split(X=df, y=df.individual_id)):\n","      df.loc[val_ , \"kfold\"] = fold"],"outputs":[],"metadata":{}},{"cell_type":"code","execution_count":9,"source":["#dataset class\n","class HappyWhaleDataset(Dataset):\n","    def __init__(self, df, transforms=None):\n","        self.df = df\n","        self.file_names = df['file_path'].values\n","        self.labels = df['individual_id'].values\n","        self.transforms = transforms\n","        \n","    def __len__(self):\n","        return len(self.df)\n","    \n","    def __getitem__(self, index):\n","        img_path = self.file_names[index]\n","        img = cv2.imread(img_path)\n","        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n","        label = self.labels[index]\n","        \n","        if self.transforms:\n","            img = self.transforms(image=img)[\"image\"]\n","            \n","        return {\n","            'image': img,\n","            'label': torch.tensor(label, dtype=torch.long)\n","        }"],"outputs":[],"metadata":{}},{"cell_type":"code","execution_count":10,"source":["#augmentations\n","data_transforms = {\n","    \"train\": A.Compose([\n","        A.Resize(CONFIG['img_size'], CONFIG['img_size']),\n","        A.ShiftScaleRotate(shift_limit=0.1, \n","                           scale_limit=0.15, \n","                           rotate_limit=60, \n","                           p=0.5),\n","        A.HueSaturationValue(\n","                hue_shift_limit=0.2, \n","                sat_shift_limit=0.2, \n","                val_shift_limit=0.2, \n","                p=0.5\n","            ),\n","        A.RandomBrightnessContrast(\n","                brightness_limit=(-0.1,0.1), \n","                contrast_limit=(-0.1, 0.1), \n","                p=0.5\n","            ),\n","        A.Normalize(\n","                mean=[0.485, 0.456, 0.406], \n","                std=[0.229, 0.224, 0.225], \n","                max_pixel_value=255.0, \n","                p=1.0\n","            ),\n","        ToTensorV2()], p=1.),\n","    \n","    \"valid\": A.Compose([\n","        A.Resize(CONFIG['img_size'], CONFIG['img_size']),\n","        A.Normalize(\n","                mean=[0.485, 0.456, 0.406], \n","                std=[0.229, 0.224, 0.225], \n","                max_pixel_value=255.0, \n","                p=1.0\n","            ),\n","        ToTensorV2()], p=1.)\n","}"],"outputs":[],"metadata":{}},{"cell_type":"code","execution_count":11,"source":["#GeM Pooling\n","class GeM(nn.Module):\n","    def __init__(self, p=3, eps=1e-6):\n","        super(GeM, self).__init__()\n","        self.p = nn.Parameter(torch.ones(1)*p)\n","        self.eps = eps\n","\n","    def forward(self, x):\n","        return self.gem(x, p=self.p, eps=self.eps)\n","        \n","    def gem(self, x, p=3, eps=1e-6):\n","        return F.avg_pool2d(x.clamp(min=eps).pow(p), (x.size(-2), x.size(-1))).pow(1./p)\n","        \n","    def __repr__(self):\n","        return self.__class__.__name__ + \\\n","                '(' + 'p=' + '{:.4f}'.format(self.p.data.tolist()[0]) + \\\n","                ', ' + 'eps=' + str(self.eps) + ')'"],"outputs":[],"metadata":{}},{"cell_type":"code","execution_count":12,"source":["#ArcFace\n","class ArcMarginProduct(nn.Module):\n","    r\"\"\"Implement of large margin arc distance: :\n","        Args:\n","            in_features: size of each input sample\n","            out_features: size of each output sample\n","            s: norm of input feature\n","            m: margin\n","            cos(theta + m)\n","        \"\"\"\n","    def __init__(self, in_features, out_features, s=30.0, \n","                 m=0.50, easy_margin=False, ls_eps=0.0):\n","        super(ArcMarginProduct, self).__init__()\n","        self.in_features = in_features\n","        self.out_features = out_features\n","        self.s = s\n","        self.m = m\n","        self.ls_eps = ls_eps  # label smoothing\n","        self.weight = nn.Parameter(torch.FloatTensor(out_features, in_features))\n","        nn.init.xavier_uniform_(self.weight)\n","\n","        self.easy_margin = easy_margin\n","        self.cos_m = math.cos(m)\n","        self.sin_m = math.sin(m)\n","        self.th = math.cos(math.pi - m)\n","        self.mm = math.sin(math.pi - m) * m\n","\n","    def forward(self, input, label):\n","        # --------------------------- cos(theta) & phi(theta) ---------------------\n","        cosine = F.linear(F.normalize(input), F.normalize(self.weight))\n","        sine = torch.sqrt(1.0 - torch.pow(cosine, 2))\n","        phi = cosine * self.cos_m - sine * self.sin_m\n","        if self.easy_margin:\n","            phi = torch.where(cosine > 0, phi, cosine)\n","        else:\n","            phi = torch.where(cosine > self.th, phi, cosine - self.mm)\n","        # --------------------------- convert label to one-hot ---------------------\n","        # one_hot = torch.zeros(cosine.size(), requires_grad=True, device='cuda')\n","        one_hot = torch.zeros(cosine.size(), device=CONFIG['device'])\n","        one_hot.scatter_(1, label.view(-1, 1).long(), 1)\n","        if self.ls_eps > 0:\n","            one_hot = (1 - self.ls_eps) * one_hot + self.ls_eps / self.out_features\n","        # -------------torch.where(out_i = {x_i if condition_i else y_i) ------------\n","        output = (one_hot * phi) + ((1.0 - one_hot) * cosine)\n","        output *= self.s\n","\n","        return output"],"outputs":[],"metadata":{}},{"cell_type":"code","execution_count":13,"source":["#Modeling\n","class HappyWhaleModel(nn.Module):\n","    def __init__(self, model_name, embedding_size, pretrained=True):\n","        super(HappyWhaleModel, self).__init__()\n","        self.model = timm.create_model(model_name, pretrained=pretrained)\n","        in_features = self.model.classifier.in_features\n","        self.model.classifier = nn.Identity()\n","        self.model.global_pool = nn.Identity()\n","        self.pooling = GeM()\n","        self.embedding = nn.Linear(in_features, embedding_size)\n","        self.fc = ArcMarginProduct(embedding_size, \n","                                   CONFIG[\"num_classes\"],\n","                                   s=CONFIG[\"s\"], \n","                                   m=CONFIG[\"m\"], \n","                                   easy_margin=CONFIG[\"ls_eps\"], \n","                                   ls_eps=CONFIG[\"ls_eps\"])\n","\n","    def forward(self, images, labels):\n","        features = self.model(images)\n","        pooled_features = self.pooling(features).flatten(1)\n","        embedding = self.embedding(pooled_features)\n","        output = self.fc(embedding, labels)\n","        return output\n","    \n","    def extract(self, images):\n","        features = self.model(images)\n","        pooled_features = self.pooling(features).flatten(1)\n","        embedding = self.embedding(pooled_features)\n","        return embedding\n","\n","    \n","model = HappyWhaleModel(CONFIG['model_name'], CONFIG['embedding_size'])\n","model.to(CONFIG['device']);"],"outputs":[{"output_type":"stream","name":"stderr","text":["Downloading: \"https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-weights/tf_efficientnet_b0_ns-c0e6a31c.pth\" to C:\\Users\\fleet/.cache\\torch\\hub\\checkpoints\\tf_efficientnet_b0_ns-c0e6a31c.pth\n"]}],"metadata":{}},{"cell_type":"code","execution_count":14,"source":["#loss function\n","def criterion(outputs, labels):\n","    return nn.CrossEntropyLoss()(outputs, labels)"],"outputs":[],"metadata":{}},{"cell_type":"code","execution_count":15,"source":["#training function\n","def train_one_epoch(model, optimizer, scheduler, dataloader, device, epoch):\n","    model.train()\n","    \n","    dataset_size = 0\n","    running_loss = 0.0\n","    \n","    bar = tqdm(enumerate(dataloader), total=len(dataloader))\n","    for step, data in bar:\n","        images = data['image'].to(device, dtype=torch.float)\n","        labels = data['label'].to(device, dtype=torch.long)\n","        \n","        batch_size = images.size(0)\n","        \n","        outputs = model(images, labels)\n","        loss = criterion(outputs, labels)\n","        loss = loss / CONFIG['n_accumulate']\n","            \n","        loss.backward()\n","    \n","        if (step + 1) % CONFIG['n_accumulate'] == 0:\n","            optimizer.step()\n","\n","            # zero the parameter gradients\n","            optimizer.zero_grad()\n","\n","            if scheduler is not None:\n","                scheduler.step()\n","                \n","        running_loss += (loss.item() * batch_size)\n","        dataset_size += batch_size\n","        \n","        epoch_loss = running_loss / dataset_size\n","        \n","        bar.set_postfix(Epoch=epoch, Train_Loss=epoch_loss,\n","                        LR=optimizer.param_groups[0]['lr'])\n","    gc.collect()\n","    \n","    return epoch_loss"],"outputs":[],"metadata":{}},{"cell_type":"code","execution_count":16,"source":["#validation function\n","@torch.inference_mode()\n","def valid_one_epoch(model, dataloader, device, epoch):\n","    model.eval()\n","    \n","    dataset_size = 0\n","    running_loss = 0.0\n","    \n","    bar = tqdm(enumerate(dataloader), total=len(dataloader))\n","    for step, data in bar:        \n","        images = data['image'].to(device, dtype=torch.float)\n","        labels = data['label'].to(device, dtype=torch.long)\n","        \n","        batch_size = images.size(0)\n","\n","        outputs = model(images, labels)\n","        loss = criterion(outputs, labels)\n","        \n","        running_loss += (loss.item() * batch_size)\n","        dataset_size += batch_size\n","        \n","        epoch_loss = running_loss / dataset_size\n","        \n","        bar.set_postfix(Epoch=epoch, Valid_Loss=epoch_loss,\n","                        LR=optimizer.param_groups[0]['lr'])   \n","    \n","    gc.collect()\n","    \n","    return epoch_loss"],"outputs":[],"metadata":{}},{"cell_type":"code","execution_count":18,"source":["#run training\n","def run_training(model, optimizer, scheduler, device, num_epochs):\n","    # To automatically log gradients\n","    wandb.watch(model, log_freq=100)\n","    \n","    if torch.cuda.is_available():\n","        print(\"[INFO] Using GPU: {}\\n\".format(torch.cuda.get_device_name()))\n","    \n","    start = time.time()\n","    best_model_wts = copy.deepcopy(model.state_dict())\n","    best_epoch_loss = np.inf\n","    history = defaultdict(list)\n","    \n","    for epoch in range(1, num_epochs + 1): \n","        gc.collect()\n","        train_epoch_loss = train_one_epoch(model, optimizer, scheduler, \n","                                           dataloader=train_loader, \n","                                           device=CONFIG['device'], epoch=epoch)\n","        \n","        val_epoch_loss = valid_one_epoch(model, valid_loader, device=CONFIG['device'], \n","                                         epoch=epoch)\n","    \n","        history['Train Loss'].append(train_epoch_loss)\n","        history['Valid Loss'].append(val_epoch_loss)\n","        \n","        # Log the metrics\n","        wandb.log({\"Train Loss\": train_epoch_loss})\n","        wandb.log({\"Valid Loss\": val_epoch_loss})\n","        \n","        # deep copy the model\n","        if val_epoch_loss <= best_epoch_loss:\n","            print(f\"{b_}Validation Loss Improved ({best_epoch_loss} ---> {val_epoch_loss})\")\n","            best_epoch_loss = val_epoch_loss\n","            run.summary[\"Best Loss\"] = best_epoch_loss\n","            best_model_wts = copy.deepcopy(model.state_dict())\n","            PATH = \"Loss{:.4f}_epoch{:.0f}.bin\".format(best_epoch_loss, epoch)\n","            torch.save(model.state_dict(), PATH)\n","            # Save a model file from the current directory\n","            print(f\"Model Saved{sr_}\")\n","            \n","        print()\n","    \n","    end = time.time()\n","    time_elapsed = end - start\n","    print('Training complete in {:.0f}h {:.0f}m {:.0f}s'.format(\n","        time_elapsed // 3600, (time_elapsed % 3600) // 60, (time_elapsed % 3600) % 60))\n","    print(\"Best Loss: {:.4f}\".format(best_epoch_loss))\n","    \n","    # load best model weights\n","    model.load_state_dict(best_model_wts)\n","    \n","    return model, history"],"outputs":[],"metadata":{}},{"cell_type":"code","execution_count":19,"source":["def fetch_scheduler(optimizer):\n","    if CONFIG['scheduler'] == 'CosineAnnealingLR':\n","        scheduler = lr_scheduler.CosineAnnealingLR(optimizer,T_max=CONFIG['T_max'], \n","                                                   eta_min=CONFIG['min_lr'])\n","    elif CONFIG['scheduler'] == 'CosineAnnealingWarmRestarts':\n","        scheduler = lr_scheduler.CosineAnnealingWarmRestarts(optimizer,T_0=CONFIG['T_0'], \n","                                                             eta_min=CONFIG['min_lr'])\n","    elif CONFIG['scheduler'] == None:\n","        return None\n","        \n","    return scheduler"],"outputs":[],"metadata":{}},{"cell_type":"code","execution_count":20,"source":["def prepare_loaders(df, fold):\n","    df_train = df[df.kfold != fold].reset_index(drop=True)\n","    df_valid = df[df.kfold == fold].reset_index(drop=True)\n","    \n","    train_dataset = HappyWhaleDataset(df_train, transforms=data_transforms[\"train\"])\n","    valid_dataset = HappyWhaleDataset(df_valid, transforms=data_transforms[\"valid\"])\n","\n","    train_loader = DataLoader(train_dataset, batch_size=CONFIG['train_batch_size'], \n","                              num_workers=2, shuffle=True, pin_memory=True, drop_last=True)\n","    valid_loader = DataLoader(valid_dataset, batch_size=CONFIG['valid_batch_size'], \n","                              num_workers=2, shuffle=False, pin_memory=True)\n","    \n","    return train_loader, valid_loader"],"outputs":[],"metadata":{}},{"cell_type":"code","execution_count":21,"source":["#prep dataloaders\n","train_loader, valid_loader = prepare_loaders(df, fold=0)"],"outputs":[],"metadata":{}},{"cell_type":"code","execution_count":22,"source":["#define optimizer and scheduler\n","optimizer = optim.Adam(model.parameters(), lr=CONFIG['learning_rate'], \n","                       weight_decay=CONFIG['weight_decay'])\n","scheduler = fetch_scheduler(optimizer)"],"outputs":[],"metadata":{}}],"nbformat":4,"nbformat_minor":2,"metadata":{"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":3},"orig_nbformat":4}}